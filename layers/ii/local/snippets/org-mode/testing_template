# -*- mode: snippet -*-
# name: testing template
# key:  testing
# --

#+TITLE: Mock Test
#+AUTHOR: ii team
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(b) | DONE(d)
#+OPTIONS: toc:nil
#+EXPORT_SELECT_TAGS: export

This issue proposes the writing of a new test for the following: API endpoints:
#+begin_comment
List endpoints picked in the sql query below.  something like:
- readCoreV1NamespacedEvent
- patchCoreV1NamespacedEvent 
- listCoreV1NamespacedEvent 
- listCoreV1EventForAllNamespaces 
- deleteCoreV1NamespacedEvent
- createCoreV1NamespacedEvent 
#+end_comment

with the intention that the test can, in two weeks time, be promoted to Conformance. This issue contains a very basic mock test in order to start the conversation about what a good e2e test would look like for this endpoint. The code below is verified to be hitting the intended endpoint, shown as per the queries in APIsnoop's live view of the cluster's audit logs.

* Identify a Feature Using APISnoop :export:

  #+begin_comment
  You can run sql blocks directly in this org-mode to help isolate good endpoints to write a test for.
  For example, we have a query called ~untested_stable_core_endpoints~.  This shows details for endpoints that are part of GA kubernetes, are not deprecated, and are not tested.

  You can select all columns for this view or a subset, below we want to see the op_id, it's method and path, and its description to help with our test-writing.
  #+end_comment
  
  According to these query results from APIsnoop, we are lacking in tests for the following endpoints...

  #+NAME: untested_stable_core_endpoints
  #+begin_src sql-mode :eval never-export :exports both
    SELECT
      operation_id,
      k8s_action,
      path,
      description
      FROM untested_stable_core_endpoints
     ORDER BY operation_id desc
     LIMIT 25
           ;
  #+end_src
  
  #+begin_comment
  You can iterate over a query until you have a set of endpoints you'd like to write a test for, usually by adjusting the columns you view or by extending the where clause to filter more specifically.
  #+end_comment

  
* Use API Reference to Lightly Document the Feature
  -  [[https://kubernetes.io/docs/reference/kubernetes-api/][Kubernetes API Reference Docs]]

* Write Your Test :export:
  #+begin_comment
  This is where the test code goes. It is useful to seperate it into blocks which can be evaluted independently.

  You can write tests in a variety of languages, outlined in [[https://kubernetes.io/docs/reference/using-api/client-libraries/]["Client Libraries"]] on k8s reference page.

  Whichever language you choose, you want to make sure to set the useragent to something starting with ~live-test~.  This ensures apisnoop's queries around testing work correctly.

  
  It can be great to break your test into individual code blocks you tanble with noweb.  This way you cna walk through the outline of the test with the relevant parts of the code.

  We've included sample tests in Go and Javascript.
  #+end_comment

** Example Test in Go
   NOTE: =, ,= or =C-c C-c= while between ~go~ *BEGIN_SRC* and *END_SRC* will
   execute the code and place the results below. (Requires ob-go)

   To set the useragent, define the config and add a useragent to it:
   : config, err := clientcmd.BuildConfigFromFlags("", *kubeconfig)
   : config.UserAgent = 'live-test-my-test'

   #+begin_src shell
     go get -v -u k8s.io/apimachinery/pkg/apis/meta/v1
     go get -v -u k8s.io/client-go/kubernetes
     go get -v -u k8s.io/client-go/tools/clientcmd
   #+end_src

   #+begin_src go  :imports '("fmt" "flag" "os" "k8s.io/apimachinery/pkg/apis/meta/v1" "k8s.io/client-go/kubernetes" "k8s.io/client-go/tools/clientcmd")
     // uses the current context in kubeconfig
     kubeconfig := flag.String("kubeconfig",
       fmt.Sprintf("%v/%v/%v", os.Getenv("HOME"), ".kube", "config"),
       "(optional) absolute path to the kubeconfig file")
     flag.Parse()
     config, err := clientcmd.BuildConfigFromFlags("", *kubeconfig)
     if err != nil {
       fmt.Println(err)
     }
     // make our work easier to find in the audit_event queries
     config.UserAgent = "live-test-pod-count"
     // creates the clientset
     clientset, _ := kubernetes.NewForConfig(config)
     // access the API to list pods
     pods, _ := clientset.CoreV1().Pods("").List(v1.ListOptions{})
     fmt.Printf("There are %d pods in the cluster\n", len(pods.Items))
   #+end_src

** Example Test in Python



#+name: use the API via python
#+begin_src python :results output :exports both :eval never-export
# required 'pip3 install kubernetes'
import kubernetes.client
from kubernetes.config import kube_config
from kubernetes.client.configuration import Configuration
k8s_config = Configuration()
kube_config.load_kube_config( client_configuration=k8s_config )
k8s_client = kubernetes.client.ApiClient( k8s_config )
v1 = kubernetes.client.CoreV1Api( k8s_client )

#print("Listing pods with their IPs:")
ret = v1.list_pod_for_all_namespaces(watch=False)
apod=v1.list_pod_for_all_namespaces(watch=False).items[0]
s=v1.read_namespaced_pod_status(apod.metadata.name, apod.metadata.namespace, pretty=True)
#print(s)
#+end_src

** Example Test in Javascript

   #+begin_comment
   Most often, To set the useragent, add it as a header in the third param given to your kubernetes-interfacing function.
   : k8sApi.readNodeStatus(node, undefined, {headers: {'User-Agent': 'live-test-my-test'}})
   : .then(resp => // do something with the response//)
   #+end_comment

   #+begin_src javascript
     const k8s = require('@kubernetes/client-node')

     const kc = new k8s.KubeConfig()
     kc.loadFromDefault()

     const k8sApi = kc.makeApiClient(k8s.CoreV1Api)
     const requestOptions = {
         headers: {
             'User-Agent': 'live-test-writing'
         }
     }

     var nodeToReadStatus

     k8sApi.listNode(undefined, undefined, undefined, undefined, undefined, undefined, undefined, undefined, undefined, requestOptions).then(res => {
         nodeToReadStatus = res.body.items[0]

         return k8sApi.readNodeStatus(nodeToReadStatus.metadata.name, undefined, requestOptions)
     }).then(res => {
         if (nodeToReadStatus.metadata.name !== res.body.metadata.name) {
             throw console.log("[status] test failed; Node names don't match.")
         }
         console.log("[status] test successful; found node")
     }).catch(err => {
         console.log(JSON.stringify(err, null, 4))
     })
   #+end_src

* Verify with APISnoop :export:

  #+begin_comment
  As you run your test functions against the cluster, apisnoop logs all endpoints hit and puts it in the db with the bucket 'apisnoop' and the job 'live'.
  We use this to build a set of queries that show what endpoints are hit by your test (or other function), and what the projected change in coverage would be if this test was merged into the e2e testing suite.
  #+end_comment

  #+begin_src sql-mode :eval never-export :exports both
    select * from endpoints_hit_by_new_test where useragent like 'live%';
  #+end_src

  #+RESULTS:
  #+begin_src sql-mode
    useragent      |         operation_id          | hit_by_ete | hit_by_new_test
      ---------------------+-------------------------------+------------+-----------------
      live-test-pod-count | listCoreV1PodForAllNamespaces |         32 |               1
      (1 row)

  #+end_src

  #+begin_comment
  NOTE: for the projected change in coverage, your test functions must be configured with a useragent that starts with ~live-test~, otherwise endpoints hit by that test won't be counted as part of new coverage.
  #+end_comment
  
  #+begin_src sql-mode :eval never-export :exports both
    select * from projected_change_in_coverage;
  #+end_src

  #+RESULTS:
  #+begin_src sql-mode
    category    | total_endpoints | old_coverage | new_coverage | change_in_number
      ---------------+-----------------+--------------+--------------+------------------
      test_coverage |             438 |          183 |          183 |                0
      (1 row)

  #+end_src

* Final Notes :export:
  #+begin_comment
  Here it could be good to restate the amount of points conformacne would go up if this test is merged.  Include any other final comment relevant for the ticket.
  #+end_comment
  
* Open Tasks
  Set any open tasks here, using org-todo
** DONE Live Your Best Life
* Footnotes :neverexport:
  :PROPERTIES:
  :CUSTOM_ID: footnotes
  :END:
** Load Logs to Help Debug Cluster
   #:PROPERTIES:
   #:header-args:tmate+: :prologue (concat "cd " (file-name-directory buffer-file-name) "../../apisnoop/apps\n. .loadenv\n")
   #:END:
*** hasura logs

    #+BEGIN_SRC tmate :eval never-export :session foo:hasura_logs
      HASURA_POD=$(\
                   kubectl get pod --selector=io.apisnoop.graphql=hasura -o name \
                       | sed s:pod/::)
      kubectl logs $HASURA_POD -f
    #+END_SRC

*** postgres logs

    #+BEGIN_SRC tmate :eval never-export :session foo:postgres_logs
      POSTGRES_POD=$(\
                     kubectl get pod --selector=io.apisnoop.db=postgres -o name \
                         | sed s:pod/::)
      kubectl logs $POSTGRES_POD -f
    #+END_SRC

** Manually load swagger or audit events
   If you ran through the full setup, but were getting 0's in the stable_endpint_stats, it means the table migrations were successful, but no data was loaded.

   You can verify data loaded with the below query.  ~bucket_job_swagger~ should have a size around 3600kb and raw_audit_event should have a size around 412mb.

   #+NAME: Verify Data Loaded
   #+begin_src sql-mode
     \dt+
   #+end_src

   #+RESULTS:
   #+begin_src sql-mode
     List of relations
       Schema |        Name        | Type  |  Owner   |  Size   | Description
       --------+--------------------+-------+----------+---------+-------------
       public | bucket_job_swagger | table | apisnoop | 3600 kB |
       public | raw_audit_event    | table | apisnoop | 412 MB  |
       (2 rows)

   #+end_src

   If either shows a size of ~8192 bytes~, you'll want to manually load it, refresh materialized views, then check again.

   if you want to load a particular bucket or job, you can name them as the first and second argument of these functions.
   e.g
   : select * from load)swagger('ci-kubernetes-beta', 1122334344);
   will load that specific bucket/job combo.
   : select * from load_swagger('ci-kubernetes-beta');
   will load the latest successful test run for ~ci-kubernetes-beta~
   : select * from load_swagger('ci-kubernetes-beta', null, true);
   will load the latest successful test run for ~ci-kubernetes-beta~, but with bucket and job set to 'apisnoop/live' (used for testing).
   #+NAME: Manually load swaggers
   #+begin_src sql-mode
     select * from load_swagger();
     select * from load_swagger(null, null, true);
   #+end_src

   #+NAME: Manually load audit events
   #+begin_src sql-mode
     select * from load_audit_events();
   #+end_src

   #+NAME: Refresh Materialized Views
   #+begin_src sql-mode
     REFRESH MATERIALIZED VIEW api_operation_material;
     REFRESH MATERIALIZED VIEW api_operation_parameter_material;
   #+end_src